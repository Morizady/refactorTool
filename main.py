#!/usr/bin/env python3
"""
æ–°æ—§ç³»ç»Ÿæ¥å£æ˜ å°„ä¸è¿ç§»å·¥å…· - æ”¯æŒå•é¡¹ç›®åˆ†æ
"""

import os
import json
from pathlib import Path
from typing import Dict, List, Optional
from dataclasses import dataclass, asdict
import argparse

from endpoint_extractor import EndpointExtractor
from equivalence_matcher import EquivalenceMatcher
from call_chain_analyzer import CallChainAnalyzer
from sql_mapper_analyzer import SQLMapperAnalyzer
from ai_generator import AIGenerator

class DeepCallChainAnalyzer:
    """æ·±åº¦è°ƒç”¨é“¾åˆ†æå™¨ - å¢å¼ºç‰ˆ"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.analyzed_methods = set()  # é¿å…å¾ªç¯åˆ†æ
        self.call_tree = {}
        self.interface_implementations = {}  # æ¥å£å®ç°æ˜ å°„
        self.class_hierarchy = {}  # ç±»ç»§æ‰¿å…³ç³»
        self._build_class_hierarchy()
        
    def _build_class_hierarchy(self):
        """æ„å»ºç±»ç»§æ‰¿å…³ç³»å’Œæ¥å£å®ç°æ˜ å°„"""
        print("ğŸ” æ„å»ºç±»ç»§æ‰¿å…³ç³»...")
        
        java_files = []
        for root, dirs, files in os.walk(self.project_root):
            for file in files:
                if file.endswith('.java'):
                    java_files.append(os.path.join(root, file))
        
        total_files = len(java_files)
        print(f"ğŸ“ æ‰¾åˆ° {total_files} ä¸ªJavaæ–‡ä»¶ï¼Œå¼€å§‹åˆ†æ...")
        
        for i, file_path in enumerate(java_files, 1):
            if i % 50 == 0 or i == total_files:  # æ¯50ä¸ªæ–‡ä»¶æˆ–æœ€åä¸€ä¸ªæ–‡ä»¶æ‰“å°è¿›åº¦
                print(f"  ğŸ“Š åˆ†æè¿›åº¦: {i}/{total_files} ({i/total_files*100:.1f}%)")
            self._analyze_class_structure(file_path)
        
        interface_count = len(self.interface_implementations)
        class_count = len(self.class_hierarchy)
        print(f"âœ… ç±»ç»§æ‰¿å…³ç³»æ„å»ºå®Œæˆ: {class_count} ä¸ªç±», {interface_count} ä¸ªæ¥å£")
    
    def _analyze_class_structure(self, file_path: str):
        """åˆ†æå•ä¸ªJavaæ–‡ä»¶çš„ç±»ç»“æ„"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            import re
            
            # æŸ¥æ‰¾ç±»å®šä¹‰å’Œæ¥å£å®ç°
            class_pattern = r'(?:public\s+)?(?:abstract\s+)?class\s+(\w+)(?:\s+extends\s+(\w+))?(?:\s+implements\s+([^{]+))?'
            interface_pattern = r'(?:public\s+)?interface\s+(\w+)(?:\s+extends\s+([^{]+))?'
            
            class_matches = re.finditer(class_pattern, content)
            for match in class_matches:
                class_name = match.group(1)
                parent_class = match.group(2)
                interfaces = match.group(3)
                
                self.class_hierarchy[class_name] = {
                    'file': file_path,
                    'parent': parent_class,
                    'interfaces': []
                }
                
                if interfaces:
                    interface_list = [i.strip() for i in interfaces.split(',')]
                    self.class_hierarchy[class_name]['interfaces'] = interface_list
                    
                    # å»ºç«‹æ¥å£åˆ°å®ç°ç±»çš„æ˜ å°„
                    for interface in interface_list:
                        if interface not in self.interface_implementations:
                            self.interface_implementations[interface] = []
                        self.interface_implementations[interface].append({
                            'class': class_name,
                            'file': file_path
                        })
            
            # æŸ¥æ‰¾æ¥å£å®šä¹‰
            interface_matches = re.finditer(interface_pattern, content)
            for match in interface_matches:
                interface_name = match.group(1)
                parent_interfaces = match.group(2)
                
                if interface_name not in self.interface_implementations:
                    self.interface_implementations[interface_name] = []
                    
        except Exception as e:
            pass  # å¿½ç•¥è§£æé”™è¯¯
    
    def analyze_method_calls(self, file_path: str, method_name: str, depth: int = 0, max_depth: int = 4) -> Dict:
        """æ·±åº¦åˆ†ææ–¹æ³•è°ƒç”¨ - å¢å¼ºç‰ˆ"""
        if depth > max_depth:
            return {"note": "è¾¾åˆ°æœ€å¤§æ·±åº¦é™åˆ¶"}
        
        # ä½¿ç”¨æ›´ç²¾ç¡®çš„å¾ªç¯æ£€æµ‹æ ‡è¯†ç¬¦
        method_key = f"{file_path}:{method_name}:{depth}"
        if method_key in self.analyzed_methods:
            return {"note": "å·²åˆ†æè¿‡ï¼Œé¿å…å¾ªç¯å¼•ç”¨"}
        
        # æ‰“å°å½“å‰åˆ†æè¿›åº¦
        indent = "  " * depth
        print(f"{indent}ğŸ” åˆ†ææ–¹æ³•: {method_name} (æ·±åº¦: {depth})")
        
        self.analyzed_methods.add(method_key)
        
        try:
            if not os.path.exists(file_path):
                return {"error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"}
            
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾æ–¹æ³•å®šä¹‰å¹¶æå–æ–¹æ³•è°ƒç”¨
            method_calls = self._extract_method_calls_from_content(content, method_name)
            
            # å»é‡å’Œè¿‡æ»¤æ–¹æ³•è°ƒç”¨
            unique_calls = self._deduplicate_method_calls(method_calls)
            print(f"{indent}  ğŸ“‹ æ‰¾åˆ° {len(method_calls)} ä¸ªæ–¹æ³•è°ƒç”¨ï¼Œå»é‡å {len(unique_calls)} ä¸ª")
            
            # é€’å½’åˆ†ææ¯ä¸ªè°ƒç”¨
            detailed_calls = []
            for i, call in enumerate(unique_calls, 1):
                if len(unique_calls) > 5 and i % 5 == 0:  # æ¯5ä¸ªè°ƒç”¨æ‰“å°ä¸€æ¬¡è¿›åº¦
                    print(f"{indent}  ğŸ“Š å¤„ç†è°ƒç”¨è¿›åº¦: {i}/{len(unique_calls)}")
                
                call_detail = {
                    "method": call["method"],
                    "object": call.get("object", ""),
                    "line": call.get("line", 0),
                    "arguments": call.get("arguments", 0),
                    "type": call.get("type", "instance")
                }
                
                # æŸ¥æ‰¾æ–¹æ³•å®ç°
                implementations = self._find_method_implementations(call, file_path)
                
                if implementations:
                    call_detail["implementations"] = []
                    
                    # å¯¹æ¯ä¸ªå®ç°è¿›è¡Œé€’å½’åˆ†æ
                    for impl in implementations:
                        impl_detail = {
                            "file": impl["file"],
                            "class": impl.get("class", ""),
                            "type": impl.get("type", "concrete")
                        }
                        
                        # é€’å½’åˆ†æå®ç°ï¼ˆé¿å…å¯¹æ ‡å‡†åº“å’Œå·²çŸ¥ç±»å‹è¿›è¡Œæ·±åº¦åˆ†æï¼‰
                        if (impl["file"] and os.path.exists(impl["file"]) and 
                            depth < max_depth and 
                            impl.get("type") not in ["standard_library", "enum_class"]):
                            
                            impl_detail["sub_calls"] = self.analyze_method_calls(
                                impl["file"], call["method"], depth + 1, max_depth
                            )
                        
                        call_detail["implementations"].append(impl_detail)
                else:
                    # å¦‚æœæ²¡æ‰¾åˆ°å®ç°ï¼Œå°è¯•åŸæœ‰çš„æŸ¥æ‰¾æ–¹å¼
                    target_file = self._find_method_implementation_legacy(call, file_path)
                    if target_file and depth < max_depth:
                        call_detail["implementation"] = target_file
                        call_detail["sub_calls"] = self.analyze_method_calls(
                            target_file, call["method"], depth + 1, max_depth
                        )
                
                detailed_calls.append(call_detail)
            
            print(f"{indent}âœ… æ–¹æ³• {method_name} åˆ†æå®Œæˆ")
            return {
                "file": file_path,
                "method": method_name,
                "calls": detailed_calls,
                "depth": depth
            }
            
        except Exception as e:
            print(f"{indent}âŒ åˆ†æå¤±è´¥: {str(e)}")
            return {"error": f"åˆ†æå¤±è´¥: {str(e)}"}
    
    def _extract_method_calls_from_content(self, content: str, method_name: str) -> List[Dict]:
        """ä»å†…å®¹ä¸­æå–æ–¹æ³•è°ƒç”¨ - å¢å¼ºç‰ˆ"""
        calls = []
        lines = content.split('\n')
        
        # æŸ¥æ‰¾æ–¹æ³•å®šä¹‰
        method_start = -1
        method_end = -1
        brace_count = 0
        in_method = False
        
        for i, line in enumerate(lines):
            # æ›´ç²¾ç¡®çš„æ–¹æ³•å®šä¹‰åŒ¹é…
            if self._is_method_definition(line, method_name):
                method_start = i
                in_method = True
                brace_count = 0
                # è®¡ç®—æ–¹æ³•å®šä¹‰è¡Œçš„å¤§æ‹¬å·
                brace_count += line.count('{') - line.count('}')
                continue
            
            if in_method:
                # è®¡ç®—å¤§æ‹¬å·
                brace_count += line.count('{') - line.count('}')
                
                # æå–æ–¹æ³•è°ƒç”¨ï¼ˆæ’é™¤æ–¹æ³•å®šä¹‰è¡Œï¼‰
                method_calls = self._parse_method_calls_in_line_enhanced(line, i + 1)
                calls.extend(method_calls)
                
                # å¦‚æœå¤§æ‹¬å·å¹³è¡¡ï¼Œè¯´æ˜æ–¹æ³•ç»“æŸ
                if brace_count == 0 and i > method_start:
                    method_end = i
                    break
        
        return calls
    
    def _is_method_definition(self, line: str, method_name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯æ–¹æ³•å®šä¹‰è¡Œ"""
        import re
        
        # æ›´ç²¾ç¡®çš„æ–¹æ³•å®šä¹‰æ¨¡å¼
        # å¿…é¡»ä»¥è®¿é—®ä¿®é¥°ç¬¦å¼€å¤´ï¼Œä¸”æ–¹æ³•åå‰æœ‰è¿”å›ç±»å‹
        patterns = [
            # public/private/protected + å¯é€‰static + è¿”å›ç±»å‹ + æ–¹æ³•å + (
            rf'^\s*(?:public|private|protected)\s+(?:static\s+)?(?:\w+(?:<[^>]*>)?\s+)+{re.escape(method_name)}\s*\(',
            # @æ³¨è§£åçš„æ–¹æ³•å®šä¹‰
            rf'^\s*(?:public|private|protected)\s+(?:static\s+)?(?:\w+(?:<[^>]*>)?\s+)*{re.escape(method_name)}\s*\(',
        ]
        
        # æ’é™¤æ˜æ˜¾ä¸æ˜¯æ–¹æ³•å®šä¹‰çš„æƒ…å†µ
        exclude_patterns = [
            r'^\s*\w+\.',  # ä»¥å¯¹è±¡.å¼€å¤´çš„è°ƒç”¨
            r'^\s*return\s+',  # returnè¯­å¥
            r'^\s*if\s*\(',  # ifè¯­å¥
            r'^\s*while\s*\(',  # whileè¯­å¥
            r'^\s*for\s*\(',  # forè¯­å¥
        ]
        
        # å…ˆæ£€æŸ¥æ’é™¤æ¨¡å¼
        for exclude_pattern in exclude_patterns:
            if re.search(exclude_pattern, line):
                return False
        
        # å†æ£€æŸ¥æ–¹æ³•å®šä¹‰æ¨¡å¼
        for pattern in patterns:
            if re.search(pattern, line):
                return True
        
        return False
        return False
    
    def _parse_method_calls_in_line_enhanced(self, line: str, line_number: int) -> List[Dict]:
        """è§£æå•è¡Œä¸­çš„æ–¹æ³•è°ƒç”¨ - å¢å¼ºç‰ˆ"""
        calls = []
        import re
        
        # å»é™¤æ³¨é‡Š
        line_clean = re.sub(r'//.*$', '', line)
        line_clean = re.sub(r'/\*.*?\*/', '', line_clean)
        
        # 1. æšä¸¾å¸¸é‡è°ƒç”¨ EnumClass.CONSTANT.method()
        enum_pattern = r'([A-Z]\w*)\.([A-Z_]+)\.(\w+)\s*\(([^)]*)\)'
        enum_matches = re.finditer(enum_pattern, line_clean)
        for match in enum_matches:
            enum_class = match.group(1)
            enum_constant = match.group(2)
            method = match.group(3)
            args = match.group(4)
            
            # æ·»åŠ æšä¸¾å¸¸é‡è°ƒç”¨
            calls.append({
                "object": enum_constant,  # ä½¿ç”¨å¸¸é‡åä½œä¸ºå¯¹è±¡
                "method": method,
                "line": line_number,
                "arguments": self._count_arguments_from_string(args),
                "type": "enum_constant",
                "enum_class": enum_class  # ä¿å­˜æšä¸¾ç±»ä¿¡æ¯
            })
        
        # 2. é“¾å¼è°ƒç”¨ object.method1().method2()
        chain_pattern = r'(\w+)(?:\.(\w+)\s*\([^)]*\))+(?:\.(\w+)\s*\([^)]*\))*'
        chain_matches = re.finditer(chain_pattern, line_clean)
        for match in chain_matches:
            # è§£æé“¾å¼è°ƒç”¨ä¸­çš„æ¯ä¸ªæ–¹æ³•
            chain_part = match.group(0)
            method_calls_in_chain = re.findall(r'\.(\w+)\s*\(([^)]*)\)', chain_part)
            
            base_object = match.group(1)
            for i, (method, args) in enumerate(method_calls_in_chain):
                calls.append({
                    "object": base_object if i == 0 else "chained",
                    "method": method,
                    "line": line_number,
                    "arguments": self._count_arguments_from_string(args),
                    "type": "chain"
                })
        
        # 3. é™æ€æ–¹æ³•è°ƒç”¨ Class.method()
        static_pattern = r'([A-Z]\w*)\.(\w+)\s*\(([^)]*)\)'
        static_matches = re.finditer(static_pattern, line_clean)
        for match in static_matches:
            # é¿å…é‡å¤æ·»åŠ å·²ç»åœ¨æšä¸¾è°ƒç”¨ä¸­å¤„ç†çš„
            if not any(call.get("enum_class") == match.group(1) and call["method"] == match.group(2) 
                      and call["line"] == line_number for call in calls):
                calls.append({
                    "object": match.group(1),
                    "method": match.group(2),
                    "line": line_number,
                    "arguments": self._count_arguments_from_string(match.group(3)),
                    "type": "static"
                })
        
        # 4. å®ä¾‹æ–¹æ³•è°ƒç”¨ object.method()
        instance_pattern = r'(\w+)\.(\w+)\s*\(([^)]*)\)'
        instance_matches = re.finditer(instance_pattern, line_clean)
        for match in instance_matches:
            # é¿å…é‡å¤æ·»åŠ å·²ç»åœ¨é“¾å¼è°ƒç”¨ä¸­å¤„ç†çš„
            if not any(call["object"] == match.group(1) and call["method"] == match.group(2) 
                      and call["line"] == line_number for call in calls):
                calls.append({
                    "object": match.group(1),
                    "method": match.group(2),
                    "line": line_number,
                    "arguments": self._count_arguments_from_string(match.group(3)),
                    "type": "instance"
                })
        
        # 5. æ„é€ å‡½æ•°è°ƒç”¨ new Class()
        constructor_pattern = r'new\s+([A-Z]\w*)\s*\(([^)]*)\)'
        constructor_matches = re.finditer(constructor_pattern, line_clean)
        for match in constructor_matches:
            calls.append({
                "object": match.group(1),
                "method": "<init>",
                "line": line_number,
                "arguments": self._count_arguments_from_string(match.group(2)),
                "type": "constructor"
            })
        
        # 6. ç›´æ¥æ–¹æ³•è°ƒç”¨ method()
        direct_pattern = r'(?<!\w)(\w+)\s*\(([^)]*)\)'
        direct_matches = re.finditer(direct_pattern, line_clean)
        for match in direct_matches:
            method_name = match.group(1)
            # æ’é™¤å…³é”®å­—ã€å·²åŒ¹é…çš„æ–¹æ³•å’Œæ„é€ å‡½æ•°
            if (method_name not in ['if', 'for', 'while', 'switch', 'catch', 'new', 'return'] and
                not any(call["method"] == method_name and call["line"] == line_number for call in calls)):
                calls.append({
                    "method": method_name,
                    "line": line_number,
                    "arguments": self._count_arguments_from_string(match.group(2)),
                    "type": "direct"
                })
        
        return calls
    
    def _deduplicate_method_calls(self, method_calls: List[Dict]) -> List[Dict]:
        """å»é‡æ–¹æ³•è°ƒç”¨ï¼Œé¿å…åŒä¸€ä¸ªè°ƒç”¨è¢«é‡å¤è¯†åˆ«"""
        # ç¬¬ä¸€æ­¥ï¼šé¢„å¤„ç†ï¼Œç»Ÿä¸€æ„é€ å‡½æ•°çš„è¡¨ç¤º
        processed_calls = []
        
        for call in method_calls:
            obj = call.get("object", "")
            method = call.get("method", "")
            call_type = call.get("type", "instance")
            line = call.get("line", 0)
            
            # ç»Ÿä¸€æ‰€æœ‰æ„é€ å‡½æ•°è°ƒç”¨çš„è¡¨ç¤º
            is_constructor = False
            
            if method == "<init>":
                # new ClassName() -> ClassName.<init>()
                is_constructor = True
                target_class = obj
            elif call_type == "direct" and obj and method == obj:
                # ClassName.ClassName() å½¢å¼
                is_constructor = True
                target_class = obj
            elif call_type == "direct" and not obj and method and method[0].isupper():
                # ServiceResult() å½¢å¼ï¼ˆæ— å¯¹è±¡åçš„æ„é€ å‡½æ•°è°ƒç”¨ï¼‰
                is_constructor = True
                target_class = method
            
            if is_constructor:
                # ç»Ÿä¸€ä¸º ClassName.ClassName() [æ„é€ ] çš„å½¢å¼
                call["object"] = target_class
                call["method"] = target_class
                call["type"] = "constructor"
            
            processed_calls.append(call)
        
        # ç¬¬äºŒæ­¥ï¼šåŸºäºå”¯ä¸€é”®å»é‡
        unique_calls = []
        seen_calls = {}
        
        for call in processed_calls:
            obj = call.get("object", "")
            method = call.get("method", "")
            line = call.get("line", 0)
            call_type = call.get("type", "instance")
            
            # åˆ›å»ºå”¯ä¸€é”®ï¼šå¯¹è±¡.æ–¹æ³•@è¡Œå·
            unique_key = f"{obj}.{method}@{line}"
            
            if unique_key in seen_calls:
                existing_call = seen_calls[unique_key]
                
                # å®šä¹‰ç±»å‹ä¼˜å…ˆçº§
                type_priority = {
                    "static": 4,
                    "enum_constant": 4,
                    "constructor": 3,
                    "instance": 2,
                    "chain": 2,
                    "direct": 1
                }
                
                current_priority = type_priority.get(call_type, 0)
                existing_priority = type_priority.get(existing_call.get("type"), 0)
                
                if current_priority > existing_priority:
                    # æ›¿æ¢ä¸ºä¼˜å…ˆçº§æ›´é«˜çš„è°ƒç”¨
                    unique_calls = [c for c in unique_calls if c != existing_call]
                    seen_calls[unique_key] = call
                    unique_calls.append(call)
            else:
                seen_calls[unique_key] = call
                unique_calls.append(call)
        
        return unique_calls

    def _count_arguments_from_string(self, args_str: str) -> int:
        """ä»å‚æ•°å­—ç¬¦ä¸²è®¡ç®—å‚æ•°æ•°é‡"""
        if not args_str.strip():
            return 0
        
        # ç®€å•çš„å‚æ•°è®¡æ•°ï¼Œè€ƒè™‘åµŒå¥—æ‹¬å·
        paren_level = 0
        comma_count = 0
        
        for char in args_str:
            if char == '(':
                paren_level += 1
            elif char == ')':
                paren_level -= 1
            elif char == ',' and paren_level == 0:
                comma_count += 1
        
        return comma_count + 1 if args_str.strip() else 0
    
        seen_calls = set()
        
        for call in method_calls:
            # åˆ›å»ºå”¯ä¸€æ ‡è¯†ç¬¦
            obj = call.get("object", "")
            method = call.get("method", "")
            line = call.get("line", 0)
            call_type = call.get("type", "instance")
            
            # å¯¹äºæ„é€ å‡½æ•°è°ƒç”¨ï¼Œç»Ÿä¸€å¤„ç†
            if method == "<init>":
                method = obj  # å°†æ„é€ å‡½æ•°è°ƒç”¨ç»Ÿä¸€ä¸ºç±»å
                call["method"] = method
                call["type"] = "constructor"
            
            # åˆ›å»ºå”¯ä¸€é”®ï¼šå¯¹è±¡.æ–¹æ³•@è¡Œå·
            unique_key = f"{obj}.{method}@{line}"
            
            if unique_key not in seen_calls:
                seen_calls.add(unique_key)
                
                # ä¼˜å…ˆä¿ç•™æ›´å…·ä½“çš„è°ƒç”¨ç±»å‹
                existing_call = None
                for existing in unique_calls:
                    if (existing.get("object") == obj and 
                        existing.get("method") == method and 
                        existing.get("line") == line):
                        existing_call = existing
                        break
                
                if existing_call:
                    # å¦‚æœå·²å­˜åœ¨ï¼Œé€‰æ‹©æ›´å…·ä½“çš„ç±»å‹
                    type_priority = {
                        "static": 3,
                        "instance": 2, 
                        "chain": 2,
                        "constructor": 2,
                        "direct": 1,
                        "enum_constant": 3
                    }
                    
                    current_priority = type_priority.get(call_type, 0)
                    existing_priority = type_priority.get(existing_call.get("type"), 0)
                    
                    if current_priority > existing_priority:
                        # æ›¿æ¢ä¸ºæ›´å…·ä½“çš„è°ƒç”¨
                        unique_calls.remove(existing_call)
                        unique_calls.append(call)
                else:
                    unique_calls.append(call)
        
        return unique_calls
    
        """ä»å‚æ•°å­—ç¬¦ä¸²è®¡ç®—å‚æ•°æ•°é‡"""
        if not args_str.strip():
            return 0
        
        # ç®€å•çš„å‚æ•°è®¡æ•°ï¼Œè€ƒè™‘åµŒå¥—æ‹¬å·
        paren_level = 0
        comma_count = 0
        
        for char in args_str:
            if char == '(':
                paren_level += 1
            elif char == ')':
                paren_level -= 1
            elif char == ',' and paren_level == 0:
                comma_count += 1
        
        return comma_count + 1 if args_str.strip() else 0
    
    def _find_method_implementations(self, call: Dict, current_file: str) -> List[Dict]:
        """æŸ¥æ‰¾æ–¹æ³•çš„æ‰€æœ‰å®ç° - æ”¯æŒæ¥å£å’Œç»§æ‰¿"""
        method_name = call["method"]
        object_name = call.get("object", "")
        call_type = call.get("type", "instance")
        enum_class = call.get("enum_class", "")  # è·å–æšä¸¾ç±»ä¿¡æ¯
        
        implementations = []
        
        # 1. å¤„ç†æšä¸¾å¸¸é‡è°ƒç”¨ (å¦‚ ResultCode.UNAUTHORIZED.getCode())
        if call_type == "enum_constant" and enum_class:
            # æŸ¥æ‰¾æšä¸¾ç±»æ–‡ä»¶
            enum_file = self._find_file_by_name(f"{enum_class}.java")
            if enum_file:
                implementations.append({
                    "file": enum_file,
                    "class": enum_class,
                    "type": "enum_class",
                    "note": f"æšä¸¾ç±»: {enum_class}.{object_name}.{method_name}()"
                })
            else:
                # å°è¯•åœ¨é¡¹ç›®ä¸­æŸ¥æ‰¾æšä¸¾ç±»
                project_enum_files = self._find_project_class_files(enum_class)
                for file_path, class_name in project_enum_files:
                    implementations.append({
                        "file": file_path,
                        "class": class_name,
                        "type": "enum_class",
                        "note": f"æšä¸¾ç±»: {class_name}.{object_name}.{method_name}()"
                    })
            return implementations
        
        # 2. å¤„ç†å·²çŸ¥çš„Javaæ ‡å‡†åº“
        if self._is_java_standard_library(object_name):
            implementations.append({
                "file": None,
                "class": object_name,
                "type": "standard_library",
                "note": f"Javaæ ‡å‡†åº“: {object_name}.{method_name}"
            })
            return implementations
        
        # 3. æŸ¥æ‰¾é¡¹ç›®ä¸­çš„å®ç°
        if object_name:
            # 2.1 Spring Serviceå˜é‡ååˆ°æ¥å£åçš„æ˜ å°„
            service_class_name = self._resolve_service_class_name(object_name, current_file)
            
            # 2.2 æŸ¥æ‰¾ç›´æ¥çš„ç±»å®ç°
            class_file = self._find_file_by_name(f"{object_name}.java")
            if class_file:
                implementations.append({
                    "file": class_file,
                    "class": object_name,
                    "type": "concrete"
                })
            
            # 2.3 å¤„ç†å¸¸è§çš„é¡¹ç›®å†…éƒ¨ç±»ï¼ˆå¦‚CommonResultã€ResultCodeç­‰ï¼‰
            project_class_files = self._find_project_class_files(object_name)
            for file_path, class_name in project_class_files:
                implementations.append({
                    "file": file_path,
                    "class": class_name,
                    "type": "project_class"
                })
            
            # 2.4 å¦‚æœæ˜¯Serviceå˜é‡ï¼ŒæŸ¥æ‰¾å¯¹åº”çš„Serviceæ¥å£å’Œå®ç°
            if service_class_name:
                # æŸ¥æ‰¾Serviceæ¥å£
                service_interface_file = self._find_file_by_name(f"{service_class_name}.java")
                if service_interface_file:
                    implementations.append({
                        "file": service_interface_file,
                        "class": service_class_name,
                        "type": "service_interface"
                    })
                
                # æŸ¥æ‰¾ServiceImplå®ç°ç±»
                impl_class_name = service_class_name + "Impl"
                impl_file = self._find_file_by_name(f"{impl_class_name}.java")
                if impl_file:
                    implementations.append({
                        "file": impl_file,
                        "class": impl_class_name,
                        "type": "service_implementation"
                    })
            
            # 2.5 é€šç”¨Serviceæ¥å£å¤„ç†
            if object_name.endswith("Service"):
                # æŸ¥æ‰¾å¯¹åº”çš„ServiceImplå®ç°ç±»
                impl_class_name = object_name + "Impl"
                impl_file = self._find_file_by_name(f"{impl_class_name}.java")
                if impl_file:
                    implementations.append({
                        "file": impl_file,
                        "class": impl_class_name,
                        "type": "service_implementation"
                    })
            
            # 2.6 æŸ¥æ‰¾æ¥å£çš„æ‰€æœ‰å®ç°
            if object_name in self.interface_implementations:
                for impl in self.interface_implementations[object_name]:
                    implementations.append({
                        "file": impl["file"],
                        "class": impl["class"],
                        "type": "interface_implementation"
                    })
            
            # 2.7 æŸ¥æ‰¾ç»§æ‰¿å…³ç³»ä¸­çš„å®ç°
            for class_name, info in self.class_hierarchy.items():
                if info.get("parent") == object_name:
                    implementations.append({
                        "file": info["file"],
                        "class": class_name,
                        "type": "inheritance"
                    })
            
            # 2.8 æ¨¡ç³ŠåŒ¹é…ï¼šæŸ¥æ‰¾åŒ…å«object_nameçš„ç±»
            if not implementations:
                # å°è¯•æŸ¥æ‰¾ç±»ä¼¼çš„ç±»å
                similar_files = self._find_similar_class_files(object_name)
                for file_path, class_name in similar_files:
                    implementations.append({
                        "file": file_path,
                        "class": class_name,
                        "type": "similar_match"
                    })
        
        # 3. åœ¨å½“å‰æ–‡ä»¶ä¸­æŸ¥æ‰¾æœ¬åœ°æ–¹æ³•
        if call_type == "direct":
            implementations.append({
                "file": current_file,
                "class": "current",
                "type": "local"
            })
        
        return implementations
    
    def _resolve_service_class_name(self, variable_name: str, current_file: str) -> Optional[str]:
        """æ ¹æ®å˜é‡åè§£æServiceç±»å"""
        # å¸¸è§çš„Spring Serviceå˜é‡åæ¨¡å¼
        service_mappings = {
            "adminService": "UmsAdminService",
            "roleService": "UmsRoleService", 
            "userService": "UmsUserService",
            "menuService": "UmsMenuService",
            "resourceService": "UmsResourceService",
        }
        
        # ç›´æ¥æ˜ å°„
        if variable_name in service_mappings:
            return service_mappings[variable_name]
        
        # æ¨¡å¼åŒ¹é…ï¼šxxxService -> XxxService
        if variable_name.endswith("Service"):
            # å°†é¦–å­—æ¯å¤§å†™
            class_name = variable_name[0].upper() + variable_name[1:]
            return class_name
        
        # å°è¯•ä»å½“å‰æ–‡ä»¶ä¸­è§£æ@Autowiredæ³¨è§£
        try:
            with open(current_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾@Autowired private XxxService xxxService;
            import re
            pattern = rf'@Autowired\s+(?:private\s+)?(\w+Service)\s+{re.escape(variable_name)}\s*;'
            match = re.search(pattern, content)
            if match:
                return match.group(1)
                
        except Exception:
            pass
        
        return None
    
    def _find_method_implementation_legacy(self, call: Dict, current_file: str) -> Optional[str]:
        """åŸæœ‰çš„æ–¹æ³•å®ç°æŸ¥æ‰¾é€»è¾‘ï¼ˆå‘åå…¼å®¹ï¼‰"""
        method_name = call["method"]
        object_name = call.get("object", "")
        
        # å¸¸è§çš„Javaå·¥å…·ç±»å’Œæ–¹æ³•æ˜ å°„
        known_implementations = {
            "System": {
                "currentTimeMillis": None,  # Javaæ ‡å‡†åº“
                "out": None
            },
            "JwtUtil": {
                "createJWT": self._find_file_by_name("JwtUtil.java")
            },
            "Jwts": {
                "builder": None,  # ç¬¬ä¸‰æ–¹åº“
                "parser": None
            },
            "SignatureAlgorithm": {
                "HS256": None
            },
            "Date": {
                "<init>": None
            },
            "HashMap": {
                "<init>": None
            }
        }
        
        # æŸ¥æ‰¾å·²çŸ¥å®ç°
        if object_name in known_implementations:
            impl = known_implementations[object_name].get(method_name)
            if impl:
                return impl
        
        # åœ¨é¡¹ç›®ä¸­æŸ¥æ‰¾å®ç°
        if object_name:
            class_file = self._find_file_by_name(f"{object_name}.java")
            if class_file:
                return class_file
        
        return None
    
    def _is_java_standard_library(self, class_name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯Javaæ ‡å‡†åº“ç±»"""
        standard_classes = {
            'System', 'String', 'Integer', 'Long', 'Double', 'Float', 'Boolean',
            'Date', 'Calendar', 'HashMap', 'ArrayList', 'List', 'Map', 'Set',
            'Thread', 'Object', 'Class', 'Math', 'Random'
        }
        return class_name in standard_classes
    
    def _find_file_by_name(self, filename: str) -> Optional[str]:
        """åœ¨é¡¹ç›®ä¸­æŸ¥æ‰¾æŒ‡å®šæ–‡ä»¶åçš„æ–‡ä»¶"""
        for root, dirs, files in os.walk(self.project_root):
            if filename in files:
                return os.path.join(root, filename)
        return None
    
    def _find_similar_class_files(self, class_name: str) -> List[tuple]:
        """æŸ¥æ‰¾ç›¸ä¼¼çš„ç±»æ–‡ä»¶ï¼Œè¿”å›(æ–‡ä»¶è·¯å¾„, ç±»å)åˆ—è¡¨"""
        similar_files = []
        
        # å¸¸è§çš„å‘½åæ¨¡å¼
        patterns = [
            f"{class_name}Impl.java",      # ServiceImplæ¨¡å¼
            f"{class_name}Implementation.java",  # ServiceImplementationæ¨¡å¼
            f"Default{class_name}.java",   # DefaultServiceæ¨¡å¼
            f"{class_name}Bean.java",      # ServiceBeanæ¨¡å¼
        ]
        
        for root, dirs, files in os.walk(self.project_root):
            for file in files:
                if file.endswith('.java'):
                    # æ£€æŸ¥æ˜¯å¦åŒ¹é…ä»»ä½•æ¨¡å¼
                    for pattern in patterns:
                        if file == pattern:
                            file_path = os.path.join(root, file)
                            class_name_from_file = file[:-5]  # å»æ‰.javaåç¼€
                            similar_files.append((file_path, class_name_from_file))
                            break
                    
                    # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ…å«ç›®æ ‡ç±»å
                    if class_name.lower() in file.lower() and file != f"{class_name}.java":
                        file_path = os.path.join(root, file)
                        class_name_from_file = file[:-5]  # å»æ‰.javaåç¼€
                        similar_files.append((file_path, class_name_from_file))
        
        return similar_files
    
    def _find_project_class_files(self, class_name: str) -> List[tuple]:
        """æŸ¥æ‰¾é¡¹ç›®ä¸­çš„ç±»æ–‡ä»¶ï¼Œè¿”å›(æ–‡ä»¶è·¯å¾„, ç±»å)åˆ—è¡¨"""
        project_files = []
        
        for root, dirs, files in os.walk(self.project_root):
            for file in files:
                if file == f"{class_name}.java":
                    file_path = os.path.join(root, file)
                    project_files.append((file_path, class_name))
        
        return project_files

def generate_call_tree(endpoint_path: str, output_dir: str = "./migration_output"):
    """ç”ŸæˆæŒ‡å®šæ¥å£çš„æ·±åº¦è°ƒç”¨é“¾æ ‘"""
    print(f"ğŸš€ å¼€å§‹ç”Ÿæˆè°ƒç”¨é“¾æ ‘: {endpoint_path}")
    
    analysis_file = f"{output_dir}/endpoint_analysis.json"
    
    if not os.path.exists(analysis_file):
        print(f"âŒ åˆ†ææ–‡ä»¶ä¸å­˜åœ¨: {analysis_file}")
        print("è¯·å…ˆè¿è¡Œå•é¡¹ç›®åˆ†æç”Ÿæˆåˆ†ææ•°æ®ï¼š")
        print("python main.py --single /path/to/project")
        return
    
    # åŠ è½½åˆ†ææ•°æ®
    print("ğŸ“‚ æ­£åœ¨åŠ è½½åˆ†ææ•°æ®...")
    try:
        with open(analysis_file, 'r', encoding='utf-8') as f:
            analysis_data = json.load(f)
        print(f"âœ… æˆåŠŸåŠ è½½ {len(analysis_data)} ä¸ªæ¥å£çš„åˆ†ææ•°æ®")
    except Exception as e:
        print(f"âŒ è¯»å–åˆ†ææ–‡ä»¶å¤±è´¥: {e}")
        return
    
    # æŸ¥æ‰¾åŒ¹é…çš„æ¥å£
    print(f"ğŸ” æ­£åœ¨æŸ¥æ‰¾åŒ¹é…çš„æ¥å£: {endpoint_path}")
    matching_endpoints = []
    for endpoint_data in analysis_data:
        endpoint = endpoint_data['endpoint']
        if endpoint_path in endpoint['path'] or endpoint_path == endpoint['path']:
            matching_endpoints.append(endpoint_data)
    
    if not matching_endpoints:
        print(f"âŒ æœªæ‰¾åˆ°åŒ¹é…çš„æ¥å£: {endpoint_path}")
        return
    
    print(f"âœ… æ‰¾åˆ° {len(matching_endpoints)} ä¸ªåŒ¹é…çš„æ¥å£")
    
    # é€‰æ‹©æ¥å£
    if len(matching_endpoints) > 1:
        print(f"ğŸ” æ‰¾åˆ° {len(matching_endpoints)} ä¸ªåŒ¹é…çš„æ¥å£:")
        for i, endpoint_data in enumerate(matching_endpoints, 1):
            endpoint = endpoint_data['endpoint']
            print(f"{i}. {endpoint['method']} {endpoint['path']} - {endpoint['name']}")
        
        try:
            choice = int(input("\nè¯·é€‰æ‹©è¦åˆ†æçš„æ¥å£ (è¾“å…¥åºå·): ")) - 1
            if 0 <= choice < len(matching_endpoints):
                selected_endpoint = matching_endpoints[choice]
            else:
                print("âŒ æ— æ•ˆçš„é€‰æ‹©")
                return
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            return
    else:
        selected_endpoint = matching_endpoints[0]
    
    # ç”Ÿæˆè°ƒç”¨æ ‘
    print("ğŸŒ³ å¼€å§‹ç”Ÿæˆæ·±åº¦è°ƒç”¨é“¾æ ‘...")
    _generate_call_tree_md(selected_endpoint, output_dir)

def _generate_call_tree_md(endpoint_data: Dict, output_dir: str):
    """ç”Ÿæˆè°ƒç”¨æ ‘çš„Markdownæ–‡ä»¶"""
    endpoint = endpoint_data['endpoint']
    call_chain = endpoint_data['call_chain']
    
    # ç¡®å®šé¡¹ç›®æ ¹ç›®å½•
    file_path = endpoint['file_path']
    project_root = None
    
    print("ğŸ“ æ­£åœ¨ç¡®å®šé¡¹ç›®æ ¹ç›®å½•...")
    # å°è¯•æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•
    path_parts = file_path.split(os.sep)
    for i, part in enumerate(path_parts):
        if part in ['src', 'main', 'java']:
            project_root = os.sep.join(path_parts[:i-2]) if i >= 2 else os.sep.join(path_parts[:i])
            break
    
    if not project_root:
        project_root = os.path.dirname(file_path)
    
    print(f"ï¿½ å¼€å§‹æ·±åº¦åˆ†:ææ¥å£: {endpoint['name']}")
    print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {project_root}")
    
    # åˆ›å»ºæ·±åº¦åˆ†æå™¨
    print("ğŸ—ï¸  æ­£åœ¨åˆå§‹åŒ–æ·±åº¦åˆ†æå™¨...")
    analyzer = DeepCallChainAnalyzer(project_root)
    
    # åˆ†æä¸»æ–¹æ³•
    print(f"ğŸš€ å¼€å§‹åˆ†æä¸»æ–¹æ³•: {endpoint['handler']}")
    print("=" * 60)
    main_analysis = analyzer.analyze_method_calls(
        file_path, 
        endpoint['handler'],
        max_depth=4  # å¢åŠ æ·±åº¦
    )
    print("=" * 60)
    
    # ç”ŸæˆMarkdownå†…å®¹
    print("ğŸ“ æ­£åœ¨ç”ŸæˆMarkdownå†…å®¹...")
    md_content = _build_call_tree_markdown(endpoint, call_chain, main_analysis)
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    output_file = f"{output_dir}/call_tree_{endpoint['handler']}.md"
    print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜åˆ°æ–‡ä»¶: {output_file}")
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(md_content)
    
    print(f"âœ… è°ƒç”¨æ ‘å·²ç”Ÿæˆ: {output_file}")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    total_calls = _count_total_calls_enhanced(main_analysis.get('calls', []))
    max_depth = _get_max_depth_enhanced(main_analysis.get('calls', []))
    interface_count = _count_interface_implementations(main_analysis.get('calls', []))
    
    print(f"ğŸ“Š åˆ†æç»Ÿè®¡:")
    print(f"  - æ€»è°ƒç”¨æ•°: {total_calls}")
    print(f"  - æœ€å¤§æ·±åº¦: {max_depth}")
    print(f"  - æ¥å£å®ç°æ•°: {interface_count}")
    print(f"  - å·²åˆ†ææ–¹æ³•æ•°: {len(analyzer.analyzed_methods)}")

def _build_call_tree_markdown(endpoint: Dict, call_chain: Dict, deep_analysis: Dict) -> str:
    """æ„å»ºè°ƒç”¨æ ‘çš„Markdownå†…å®¹ - å¢å¼ºç‰ˆ"""
    lines = []
    
    # æ ‡é¢˜
    lines.append(f"# {endpoint['name']} æ·±åº¦è°ƒç”¨é“¾åˆ†æ")
    lines.append("")
    
    # åŸºæœ¬ä¿¡æ¯
    lines.append("## æ¥å£åŸºæœ¬ä¿¡æ¯")
    lines.append("")
    lines.append(f"- **æ¥å£åç§°**: {endpoint['name']}")
    lines.append(f"- **è¯·æ±‚è·¯å¾„**: {endpoint['method']} {endpoint['path']}")
    lines.append(f"- **æ§åˆ¶å™¨**: {endpoint['controller']}")
    lines.append(f"- **å¤„ç†æ–¹æ³•**: {endpoint['handler']}")
    lines.append(f"- **æºæ–‡ä»¶**: {endpoint['file_path']}")
    lines.append(f"- **è¡Œå·**: {endpoint['line_number']}")
    lines.append("")
    
    # æµ…å±‚è°ƒç”¨é“¾ï¼ˆåŸæœ‰æ•°æ®ï¼‰
    lines.append("## æµ…å±‚è°ƒç”¨é“¾")
    lines.append("")
    method_calls = call_chain.get('method_calls', [])
    if method_calls:
        lines.append("```")
        for i, call in enumerate(method_calls, 1):
            obj = call.get('object', '')
            method = call.get('method', '')
            args = call.get('arguments', 0)
            line = call.get('position', 0)
            if obj:
                lines.append(f"{i:2d}. {obj}.{method}() - {args}ä¸ªå‚æ•° (è¡Œ:{line})")
            else:
                lines.append(f"{i:2d}. {method}() - {args}ä¸ªå‚æ•° (è¡Œ:{line})")
        lines.append("```")
    else:
        lines.append("æ— æ–¹æ³•è°ƒç”¨")
    lines.append("")
    
    # æ·±åº¦è°ƒç”¨æ ‘
    lines.append("## æ·±åº¦è°ƒç”¨æ ‘")
    lines.append("")
    
    if "error" in deep_analysis:
        lines.append(f"âŒ åˆ†æå¤±è´¥: {deep_analysis['error']}")
    else:
        lines.append("```")
        lines.append(f"ğŸ“ {endpoint['handler']}() - ä¸»æ–¹æ³•")
        _build_tree_recursive_enhanced(deep_analysis.get('calls', []), lines, "  ", set(), endpoint['handler'])
        lines.append("```")
    
    lines.append("")
    
    # æ¥å£å®ç°åˆ†æ
    lines.append("## æ¥å£å®ç°åˆ†æ")
    lines.append("")
    _build_implementation_analysis(deep_analysis.get('calls', []), lines)
    
    # è°ƒç”¨é“¾è¯¦ç»†è¯´æ˜
    lines.append("## è°ƒç”¨é“¾è¯¦ç»†è¯´æ˜")
    lines.append("")
    _build_detailed_explanation_enhanced(deep_analysis.get('calls', []), lines, 1)
    
    # æ€§èƒ½åˆ†æå»ºè®®
    lines.append("## æ€§èƒ½åˆ†æå»ºè®®")
    lines.append("")
    total_calls = _count_total_calls_enhanced(deep_analysis.get('calls', []))
    max_depth = _get_max_depth_enhanced(deep_analysis.get('calls', []))
    
    if total_calls > 30:
        lines.append("âš ï¸ **é«˜å¤æ‚åº¦æ¥å£**: è°ƒç”¨é“¾éå¸¸å¤æ‚ï¼Œå¼ºçƒˆå»ºè®®é‡æ„")
    elif total_calls > 20:
        lines.append("âš¡ **ä¸­é«˜å¤æ‚åº¦**: è°ƒç”¨é“¾è¾ƒæ·±ï¼Œå»ºè®®è€ƒè™‘é‡æ„")
    elif total_calls > 10:
        lines.append("âš¡ **ä¸­ç­‰å¤æ‚åº¦**: è°ƒç”¨é“¾é€‚ä¸­ï¼Œæ³¨æ„æ€§èƒ½ç›‘æ§")
    else:
        lines.append("âœ… **ç®€å•æ¥å£**: è°ƒç”¨é“¾ç®€æ´ï¼Œæ€§èƒ½è‰¯å¥½")
    
    lines.append(f"- æ€»è°ƒç”¨æ•°: {total_calls}")
    lines.append(f"- æœ€å¤§æ·±åº¦: {max_depth}")
    lines.append(f"- æ¥å£å®ç°æ•°: {_count_interface_implementations(deep_analysis.get('calls', []))}")
    lines.append("")
    
    # ä¼˜åŒ–å»ºè®®
    lines.append("### ä¼˜åŒ–å»ºè®®")
    lines.append("")
    lines.append("1. **å‡å°‘ä¸å¿…è¦çš„æ–¹æ³•è°ƒç”¨**: åˆå¹¶ç›¸ä¼¼çš„æ“ä½œ")
    lines.append("2. **ç¼“å­˜é‡å¤è®¡ç®—**: å¯¹äºé‡å¤çš„è®¡ç®—ç»“æœè¿›è¡Œç¼“å­˜")
    lines.append("3. **å¼‚æ­¥å¤„ç†**: å¯¹äºè€—æ—¶æ“ä½œè€ƒè™‘å¼‚æ­¥å¤„ç†")
    lines.append("4. **æ‰¹é‡æ“ä½œ**: å‡å°‘æ•°æ®åº“äº¤äº’æ¬¡æ•°")
    lines.append("5. **æ¥å£ä¼˜åŒ–**: è€ƒè™‘ä½¿ç”¨å…·ä½“å®ç°ç±»è€Œéæ¥å£è°ƒç”¨")
    lines.append("")
    
    return "\n".join(lines)

def _build_tree_recursive_enhanced(calls: List[Dict], lines: List[str], indent: str, visited_methods: set = None, current_method: str = ""):
    """é€’å½’æ„å»ºè°ƒç”¨æ ‘ - å¢å¼ºç‰ˆï¼Œé¿å…é‡å¤æ˜¾ç¤º"""
    if visited_methods is None:
        visited_methods = set()
    
    for call in calls:
        method = call.get('method', 'unknown')
        obj = call.get('object', '')
        line_num = call.get('line', 0)
        args = call.get('arguments', 0)
        call_type = call.get('type', 'instance')
        
        # æ„å»ºè°ƒç”¨æ˜¾ç¤º
        if obj:
            call_display = f"{obj}.{method}()"
        else:
            call_display = f"{method}()"
        
        # åˆ›å»ºæ–¹æ³•æ ‡è¯†ç¬¦ç”¨äºé¿å…é‡å¤æ˜¾ç¤º
        method_id = f"{obj}.{method}" if obj else method
        
        # è·³è¿‡é€’å½’è°ƒç”¨è‡ªå·±çš„æƒ…å†µ
        if method == current_method and call_type == "direct":
            lines.append(f"{indent}â”œâ”€â”€ {call_display} [é€’å½’è°ƒç”¨] - {args}ä¸ªå‚æ•° (è¡Œ:{line_num})")
            continue
        
        # æ·»åŠ ç±»å‹æ ‡è¯†
        type_marker = ""
        if call_type == "static":
            type_marker = " [é™æ€]"
        elif call_type == "constructor":
            type_marker = " [æ„é€ ]"
        elif call_type == "chain":
            type_marker = " [é“¾å¼]"
        elif call_type == "enum_constant":
            type_marker = " [æšä¸¾]"
        
        lines.append(f"{indent}â”œâ”€â”€ {call_display}{type_marker} - {args}ä¸ªå‚æ•° (è¡Œ:{line_num})")
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¾ç¤ºè¿‡è¿™ä¸ªæ–¹æ³•ï¼ˆé¿å…å¾ªç¯æ˜¾ç¤ºï¼‰
        full_method_id = f"{method_id}@{line_num}"
        if full_method_id in visited_methods:
            lines.append(f"{indent}  â””â”€â”€ [å·²åˆ†æè¿‡ï¼Œé¿å…é‡å¤æ˜¾ç¤º]")
            continue
        
        visited_methods.add(full_method_id)
        
        # å¤„ç†å¤šä¸ªå®ç°
        implementations = call.get('implementations', [])
        if implementations:
            # è¿‡æ»¤æ‰æ ‡å‡†åº“å’Œæšä¸¾ç±»çš„å®ç°ï¼Œé¿å…è¿‡åº¦å±•å¼€
            filtered_impls = [impl for impl in implementations 
                            if impl.get('type') not in ['standard_library', 'enum_class']]
            
            if not filtered_impls:
                # å¦‚æœåªæœ‰æ ‡å‡†åº“å®ç°ï¼Œç®€å•æ˜¾ç¤º
                std_impls = [impl for impl in implementations 
                           if impl.get('type') in ['standard_library', 'enum_class']]
                if std_impls:
                    impl = std_impls[0]
                    impl_class = impl.get('class', 'unknown')
                    impl_type = impl.get('type', 'concrete')
                    type_desc = 'æ ‡å‡†åº“' if impl_type == 'standard_library' else 'æšä¸¾ç±»'
                    lines.append(f"{indent}  â””â”€â”€ {impl_class} ({type_desc})")
                continue
            
            # åªæ˜¾ç¤ºæœ€ç›¸å…³çš„å®ç°ï¼ˆé€šå¸¸æ˜¯ç¬¬ä¸€ä¸ªï¼‰
            impl = filtered_impls[0]
            impl_type = impl.get('type', 'concrete')
            impl_class = impl.get('class', 'unknown')
            
            type_desc = {
                'concrete': 'å…·ä½“å®ç°',
                'interface_implementation': 'æ¥å£å®ç°',
                'inheritance': 'ç»§æ‰¿å®ç°',
                'local': 'æœ¬åœ°æ–¹æ³•',
                'service_implementation': 'Serviceå®ç°',
                'service_interface': 'Serviceæ¥å£',
                'project_class': 'é¡¹ç›®ç±»',
                'similar_match': 'ç›¸ä¼¼åŒ¹é…'
            }.get(impl_type, 'æœªçŸ¥ç±»å‹')
            
            # å¯¹äºæœ¬åœ°æ–¹æ³•ï¼Œä¸æ˜¾ç¤ºå®ç°è¯¦æƒ…ï¼Œç›´æ¥å±•å¼€å­è°ƒç”¨
            if impl_type == 'local':
                sub_calls = impl.get('sub_calls', {})
                if isinstance(sub_calls, dict) and 'calls' in sub_calls:
                    # è¿‡æ»¤æ‰ä¸å½“å‰æ–¹æ³•ç›¸åŒçš„è°ƒç”¨ï¼Œé¿å…æ— é™é€’å½’æ˜¾ç¤º
                    filtered_sub_calls = [sc for sc in sub_calls['calls'] 
                                        if sc.get('method') != method or sc.get('object') != obj]
                    if filtered_sub_calls:
                        _build_tree_recursive_enhanced(filtered_sub_calls, lines, indent + "  ", visited_methods.copy(), method)
                elif isinstance(sub_calls, dict) and 'note' in sub_calls:
                    lines.append(f"{indent}  â””â”€â”€ {sub_calls['note']}")
            else:
                lines.append(f"{indent}  â””â”€â”€ {impl_class} ({type_desc})")
                
                # é€’å½’å¤„ç†å­è°ƒç”¨
                sub_calls = impl.get('sub_calls', {})
                if isinstance(sub_calls, dict) and 'calls' in sub_calls:
                    _build_tree_recursive_enhanced(sub_calls['calls'], lines, indent + "    ", visited_methods.copy(), method)
                elif isinstance(sub_calls, dict) and 'note' in sub_calls:
                    lines.append(f"{indent}    â””â”€â”€ {sub_calls['note']}")
        else:
            # å¤„ç†å•ä¸ªå®ç°ï¼ˆå‘åå…¼å®¹ï¼‰
            sub_calls = call.get('sub_calls', {})
            if isinstance(sub_calls, dict) and 'calls' in sub_calls:
                # è¿‡æ»¤æ‰ä¸å½“å‰æ–¹æ³•ç›¸åŒçš„è°ƒç”¨
                filtered_sub_calls = [sc for sc in sub_calls['calls'] 
                                    if sc.get('method') != method or sc.get('object') != obj]
                if filtered_sub_calls:
                    _build_tree_recursive_enhanced(filtered_sub_calls, lines, indent + "  ", visited_methods.copy(), method)
            elif isinstance(sub_calls, dict) and 'note' in sub_calls:
                lines.append(f"{indent}  â””â”€â”€ {sub_calls['note']}")
        
        # ä»å·²è®¿é—®é›†åˆä¸­ç§»é™¤ï¼Œå…è®¸åœ¨ä¸åŒåˆ†æ”¯ä¸­é‡æ–°æ˜¾ç¤º
        visited_methods.discard(full_method_id)

def _build_implementation_analysis(calls: List[Dict], lines: List[str]):
    """æ„å»ºæ¥å£å®ç°åˆ†æ"""
    interface_calls = []
    concrete_calls = []
    
    def collect_implementations(call_list, depth=0):
        for call in call_list:
            implementations = call.get('implementations', [])
            if implementations:
                for impl in implementations:
                    if impl.get('type') == 'interface_implementation':
                        interface_calls.append({
                            'method': call.get('method', 'unknown'),
                            'object': call.get('object', ''),
                            'implementation': impl,
                            'depth': depth
                        })
                    elif impl.get('type') == 'concrete':
                        concrete_calls.append({
                            'method': call.get('method', 'unknown'),
                            'object': call.get('object', ''),
                            'implementation': impl,
                            'depth': depth
                        })
                    
                    # é€’å½’æ”¶é›†
                    sub_calls = impl.get('sub_calls', {})
                    if isinstance(sub_calls, dict) and 'calls' in sub_calls:
                        collect_implementations(sub_calls['calls'], depth + 1)
    
    collect_implementations(calls)
    
    if interface_calls:
        lines.append("### æ¥å£è°ƒç”¨")
        lines.append("")
        for call in interface_calls[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ª
            method = call['method']
            obj = call['object']
            impl_class = call['implementation'].get('class', 'unknown')
            lines.append(f"- **{obj}.{method}()** â†’ {impl_class} (æ·±åº¦: {call['depth']})")
        
        if len(interface_calls) > 5:
            lines.append(f"- ... è¿˜æœ‰ {len(interface_calls) - 5} ä¸ªæ¥å£è°ƒç”¨")
        lines.append("")
    
    if concrete_calls:
        lines.append("### å…·ä½“ç±»è°ƒç”¨")
        lines.append("")
        for call in concrete_calls[:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ª
            method = call['method']
            obj = call['object']
            impl_class = call['implementation'].get('class', 'unknown')
            lines.append(f"- **{obj}.{method}()** â†’ {impl_class} (æ·±åº¦: {call['depth']})")
        
        if len(concrete_calls) > 5:
            lines.append(f"- ... è¿˜æœ‰ {len(concrete_calls) - 5} ä¸ªå…·ä½“ç±»è°ƒç”¨")
        lines.append("")

def _build_detailed_explanation_enhanced(calls: List[Dict], lines: List[str], level: int):
    """æ„å»ºè¯¦ç»†è¯´æ˜ - å¢å¼ºç‰ˆ"""
    for i, call in enumerate(calls, 1):
        method = call.get('method', 'unknown')
        obj = call.get('object', '')
        call_type = call.get('type', 'instance')
        
        lines.append(f"### {level}.{i} {obj}.{method}() è°ƒç”¨" if obj else f"### {level}.{i} {method}() è°ƒç”¨")
        lines.append("")
        
        lines.append(f"- **è°ƒç”¨ç±»å‹**: {call_type}")
        lines.append(f"- **å‚æ•°æ•°é‡**: {call.get('arguments', 0)}")
        lines.append(f"- **è°ƒç”¨è¡Œå·**: {call.get('line', 0)}")
        
        # å®ç°ä¿¡æ¯
        implementations = call.get('implementations', [])
        if implementations:
            lines.append(f"- **å®ç°æ•°é‡**: {len(implementations)}")
            lines.append("")
            lines.append("**å®ç°è¯¦æƒ…**:")
            
            for j, impl in enumerate(implementations, 1):
                impl_type = impl.get('type', 'concrete')
                impl_class = impl.get('class', 'unknown')
                impl_file = impl.get('file', '')
                
                lines.append(f"  {j}. **{impl_class}** ({impl_type})")
                if impl_file:
                    lines.append(f"     - æ–‡ä»¶: {impl_file}")
                
                # å­è°ƒç”¨ç»Ÿè®¡
                sub_calls = impl.get('sub_calls', {})
                if isinstance(sub_calls, dict) and 'calls' in sub_calls:
                    sub_count = len(sub_calls['calls'])
                    lines.append(f"     - å­è°ƒç”¨: {sub_count} ä¸ª")
        else:
            # å‘åå…¼å®¹
            impl = call.get('implementation', '')
            if impl:
                lines.append(f"- **å®ç°ä½ç½®**: {impl}")
        
        lines.append("")

def _count_total_calls_enhanced(calls: List[Dict]) -> int:
    """è®¡ç®—æ€»è°ƒç”¨æ•° - å¢å¼ºç‰ˆ"""
    total = len(calls)
    for call in calls:
        implementations = call.get('implementations', [])
        if implementations:
            for impl in implementations:
                sub_calls = impl.get('sub_calls', {})
                if isinstance(sub_calls, dict) and 'calls' in sub_calls:
                    total += _count_total_calls_enhanced(sub_calls['calls'])
        else:
            # å‘åå…¼å®¹
            sub_calls = call.get('sub_calls', {})
            if isinstance(sub_calls, dict) and 'calls' in sub_calls:
                total += _count_total_calls_enhanced(sub_calls['calls'])
    return total

def _get_max_depth_enhanced(calls: List[Dict], current_depth: int = 1) -> int:
    """è·å–æœ€å¤§æ·±åº¦ - å¢å¼ºç‰ˆ"""
    max_depth = current_depth
    for call in calls:
        implementations = call.get('implementations', [])
        if implementations:
            for impl in implementations:
                sub_calls = impl.get('sub_calls', {})
                if isinstance(sub_calls, dict) and 'calls' in sub_calls:
                    depth = _get_max_depth_enhanced(sub_calls['calls'], current_depth + 1)
                    max_depth = max(max_depth, depth)
        else:
            # å‘åå…¼å®¹
            sub_calls = call.get('sub_calls', {})
            if isinstance(sub_calls, dict) and 'calls' in sub_calls:
                depth = _get_max_depth_enhanced(sub_calls['calls'], current_depth + 1)
                max_depth = max(max_depth, depth)
    return max_depth

def _count_interface_implementations(calls: List[Dict]) -> int:
    """ç»Ÿè®¡æ¥å£å®ç°æ•°é‡"""
    count = 0
    
    def count_recursive(call_list):
        nonlocal count
        for call in call_list:
            implementations = call.get('implementations', [])
            for impl in implementations:
                if impl.get('type') == 'interface_implementation':
                    count += 1
                
                sub_calls = impl.get('sub_calls', {})
                if isinstance(sub_calls, dict) and 'calls' in sub_calls:
                    count_recursive(sub_calls['calls'])
    
    count_recursive(calls)
    return count

def show_endpoint_details(endpoint_path: str, output_dir: str = "./migration_output"):
    """æ˜¾ç¤ºç‰¹å®šæ¥å£çš„ä»£ç å’Œè°ƒç”¨é“¾"""
    analysis_file = f"{output_dir}/endpoint_analysis.json"
    
    if not os.path.exists(analysis_file):
        print(f"âŒ åˆ†ææ–‡ä»¶ä¸å­˜åœ¨: {analysis_file}")
        print("è¯·å…ˆè¿è¡Œå•é¡¹ç›®åˆ†æç”Ÿæˆåˆ†ææ•°æ®ï¼š")
        print("python main.py --single /path/to/project")
        return
    
    # åŠ è½½åˆ†ææ•°æ®
    try:
        with open(analysis_file, 'r', encoding='utf-8') as f:
            analysis_data = json.load(f)
    except Exception as e:
        print(f"âŒ è¯»å–åˆ†ææ–‡ä»¶å¤±è´¥: {e}")
        return
    
    # æŸ¥æ‰¾åŒ¹é…çš„æ¥å£
    matching_endpoints = []
    for endpoint_data in analysis_data:
        endpoint = endpoint_data['endpoint']
        if endpoint_path in endpoint['path'] or endpoint_path == endpoint['path']:
            matching_endpoints.append(endpoint_data)
    
    if not matching_endpoints:
        print(f"âŒ æœªæ‰¾åˆ°åŒ¹é…çš„æ¥å£: {endpoint_path}")
        print("\nå¯ç”¨çš„æ¥å£è·¯å¾„:")
        for endpoint_data in analysis_data[:10]:  # æ˜¾ç¤ºå‰10ä¸ªä½œä¸ºç¤ºä¾‹
            endpoint = endpoint_data['endpoint']
            print(f"  - {endpoint['method']} {endpoint['path']}")
        if len(analysis_data) > 10:
            print(f"  ... è¿˜æœ‰ {len(analysis_data) - 10} ä¸ªæ¥å£")
        return
    
    # æ˜¾ç¤ºåŒ¹é…çš„æ¥å£
    if len(matching_endpoints) > 1:
        print(f"ğŸ” æ‰¾åˆ° {len(matching_endpoints)} ä¸ªåŒ¹é…çš„æ¥å£:")
        for i, endpoint_data in enumerate(matching_endpoints, 1):
            endpoint = endpoint_data['endpoint']
            print(f"{i}. {endpoint['method']} {endpoint['path']} - {endpoint['name']}")
        
        try:
            choice = int(input("\nè¯·é€‰æ‹©è¦æŸ¥çœ‹çš„æ¥å£ (è¾“å…¥åºå·): ")) - 1
            if 0 <= choice < len(matching_endpoints):
                selected_endpoint = matching_endpoints[choice]
            else:
                print("âŒ æ— æ•ˆçš„é€‰æ‹©")
                return
        except ValueError:
            print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            return
    else:
        selected_endpoint = matching_endpoints[0]
    
    # æ˜¾ç¤ºæ¥å£è¯¦ç»†ä¿¡æ¯
    _display_endpoint_details(selected_endpoint)

def _display_endpoint_details(endpoint_data: Dict):
    """æ˜¾ç¤ºæ¥å£çš„è¯¦ç»†ä¿¡æ¯"""
    endpoint = endpoint_data['endpoint']
    call_chain = endpoint_data['call_chain']
    sql_mappings = endpoint_data.get('sql_mappings', [])
    complexity_score = endpoint_data['complexity_score']
    
    print(f"\n{'='*80}")
    print(f"ğŸ” æ¥å£è¯¦ç»†ä¿¡æ¯")
    print(f"{'='*80}")
    
    # åŸºæœ¬ä¿¡æ¯
    print(f"ğŸ“‹ åŸºæœ¬ä¿¡æ¯:")
    print(f"  æ¥å£åç§°: {endpoint['name']}")
    print(f"  è¯·æ±‚è·¯å¾„: {endpoint['method']} {endpoint['path']}")
    print(f"  æ§åˆ¶å™¨: {endpoint['controller']}")
    print(f"  å¤„ç†æ–¹æ³•: {endpoint['handler']}")
    print(f"  æºæ–‡ä»¶: {endpoint['file_path']}")
    print(f"  è¡Œå·: {endpoint['line_number']}")
    print(f"  å¤æ‚åº¦: {complexity_score}")
    print(f"  æ¡†æ¶: {endpoint['framework']}")
    print()
    
    # è°ƒç”¨é“¾åˆ†æ
    print(f"ğŸ”— è°ƒç”¨é“¾åˆ†æ:")
    method_calls = call_chain.get('method_calls', [])
    if method_calls:
        print(f"  æ–¹æ³•è°ƒç”¨ ({len(method_calls)}ä¸ª):")
        for i, call in enumerate(method_calls, 1):
            obj = call.get('object', 'unknown')
            method = call.get('method', 'unknown')
            args = call.get('arguments', 0)
            position = call.get('position', 0)
            print(f"    {i:2d}. {obj}.{method}() - {args}ä¸ªå‚æ•° (è¡Œ:{position})")
    else:
        print("  æ— å¤æ‚æ–¹æ³•è°ƒç”¨")
    print()
    
    # ç›¸å…³æ–‡ä»¶
    files = call_chain.get('files', [])
    if files:
        print(f"ğŸ“ ç›¸å…³æ–‡ä»¶ ({len(files)}ä¸ª):")
        # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤º
        service_files = [f for f in files if 'service' in f.get('path', '').lower()]
        dto_files = [f for f in files if 'dto' in f.get('path', '').lower()]
        vo_files = [f for f in files if 'vo' in f.get('path', '').lower()]
        mapper_files = [f for f in files if 'mapper' in f.get('path', '').lower()]
        
        if service_files:
            print("  Serviceå±‚:")
            for file in service_files[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ª
                file_name = Path(file['path']).name
                print(f"    - {file_name}")
        
        if dto_files:
            print("  DTOå¯¹è±¡:")
            for file in dto_files[:3]:
                file_name = Path(file['path']).name
                print(f"    - {file_name}")
        
        if vo_files:
            print("  VOå¯¹è±¡:")
            for file in vo_files[:3]:
                file_name = Path(file['path']).name
                print(f"    - {file_name}")
        
        if mapper_files:
            print("  Mapperå±‚:")
            for file in mapper_files[:3]:
                file_name = Path(file['path']).name
                print(f"    - {file_name}")
    print()
    
    # SQLæ˜ å°„ä¿¡æ¯
    if sql_mappings:
        print(f"ğŸ—„ï¸  SQLæ˜ å°„ä¿¡æ¯:")
        for mapping in sql_mappings[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ª
            file_path = mapping.get('file_path', '')
            file_name = Path(file_path).name if file_path else 'unknown'
            methods = mapping.get('methods', [])
            print(f"  {file_name}:")
            for method in methods[:2]:  # æ¯ä¸ªæ–‡ä»¶æœ€å¤šæ˜¾ç¤º2ä¸ªæ–¹æ³•
                method_id = method.get('id', 'unknown')
                sql_type = method.get('type', 'unknown')
                sql = method.get('sql', '')[:60] + '...' if len(method.get('sql', '')) > 60 else method.get('sql', '')
                print(f"    - {method_id} ({sql_type}): {sql}")
    print()
    
    # å°è¯•è¯»å–å¹¶æ˜¾ç¤ºæºä»£ç 
    _display_source_code(endpoint)

def _display_source_code(endpoint: Dict):
    """æ˜¾ç¤ºæºä»£ç """
    file_path = endpoint['file_path']
    line_number = endpoint['line_number']
    handler_name = endpoint['handler']
    
    print(f"ğŸ“ æºä»£ç ç‰‡æ®µ:")
    
    try:
        # å°è¯•è¯»å–æºæ–‡ä»¶
        if os.path.exists(file_path):
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # æŸ¥æ‰¾æ–¹æ³•å®šä¹‰
            method_start = -1
            method_end = -1
            brace_count = 0
            in_method = False
            
            # ä»æŒ‡å®šè¡Œå·å¼€å§‹å‘å‰æŸ¥æ‰¾æ–¹æ³•å®šä¹‰
            for i in range(max(0, line_number - 10), min(len(lines), line_number + 50)):
                line = lines[i].strip()
                
                # æŸ¥æ‰¾æ–¹æ³•å®šä¹‰
                if handler_name in lines[i] and ('public' in lines[i] or 'private' in lines[i] or 'protected' in lines[i]):
                    method_start = i
                    in_method = True
                    brace_count = 0
                
                if in_method:
                    # è®¡ç®—å¤§æ‹¬å·
                    brace_count += line.count('{') - line.count('}')
                    
                    # å¦‚æœå¤§æ‹¬å·å¹³è¡¡ï¼Œè¯´æ˜æ–¹æ³•ç»“æŸ
                    if brace_count == 0 and method_start != -1 and i > method_start:
                        method_end = i
                        break
            
            # æ˜¾ç¤ºæ–¹æ³•ä»£ç 
            if method_start != -1:
                print(f"  æ–‡ä»¶: {Path(file_path).name}")
                print(f"  æ–¹æ³•: {handler_name} (è¡Œ {method_start + 1}-{method_end + 1 if method_end != -1 else '?'})")
                print("  " + "-" * 60)
                
                end_line = method_end if method_end != -1 else min(method_start + 20, len(lines))
                for i in range(method_start, end_line + 1):
                    if i < len(lines):
                        line_num = i + 1
                        code_line = lines[i].rstrip()
                        # é«˜äº®å½“å‰è¡Œ
                        marker = ">>>" if line_num == line_number else "   "
                        print(f"  {marker} {line_num:3d}: {code_line}")
            else:
                print(f"  âŒ æ— æ³•æ‰¾åˆ°æ–¹æ³• {handler_name} çš„å®šä¹‰")
        else:
            print(f"  âŒ æºæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    except Exception as e:
        print(f"  âŒ è¯»å–æºæ–‡ä»¶å¤±è´¥: {e}")
    
    print(f"\n{'='*80}")
    print("âœ… æ¥å£åˆ†æå®Œæˆ")
    print(f"{'='*80}\n")

@dataclass
class Config:
    """é…ç½®ç±»"""
    old_project_path: Optional[str] = None
    new_project_path: Optional[str] = None
    single_project_path: Optional[str] = None  # æ–°å¢ï¼šå•é¡¹ç›®æ¨¡å¼
    output_dir: str = "./migration_output"
    ai_model: str = "gpt-3.5-turbo"
    api_key: Optional[str] = None
    context_window: int = 4000
    verbose: bool = False
    analyze_only: bool = False  # ä»…åˆ†ææ¨¡å¼
    single_mode: bool = False   # æ–°å¢ï¼šå•é¡¹ç›®æ¨¡å¼æ ‡å¿—

class MigrationTool:
    """è¿ç§»å·¥å…·ä¸»ç±»"""
    
    def __init__(self, config: Config):
        self.config = config
        self.endpoint_extractor = EndpointExtractor()
        self.equivalence_matcher = EquivalenceMatcher()
        self.call_chain_analyzer = CallChainAnalyzer()
        self.sql_mapper_analyzer = SQLMapperAnalyzer()
        
        # ä»…åœ¨é…ç½®äº†APIå¯†é’¥æ—¶åˆå§‹åŒ–AIç”Ÿæˆå™¨
        if not config.analyze_only and (config.api_key or os.getenv("OPENAI_API_KEY")):
            self.ai_generator = AIGenerator(
                model=config.ai_model,
                api_key=config.api_key or os.getenv("OPENAI_API_KEY")
            )
        else:
            self.ai_generator = None
            if not config.single_mode:
                print("âš ï¸  AIåŠŸèƒ½å·²ç¦ç”¨ï¼Œä»…æ‰§è¡Œåˆ†æ")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(config.output_dir, exist_ok=True)
        
    def run(self):
        """è¿è¡Œå®Œæ•´çš„è¿ç§»æµç¨‹"""
        if self.config.single_mode:
            self.run_single_project_analysis()
        else:
            self.run_migration_analysis()
    
    def run_single_project_analysis(self):
        """è¿è¡Œå•é¡¹ç›®åˆ†æ"""
        print("ğŸš€ å¼€å§‹åˆ†æé¡¹ç›®æ¥å£...")
        
        # æå–æ¥å£
        print("ğŸ“‹ æå–é¡¹ç›®æ¥å£...")
        endpoints = self.endpoint_extractor.extract_from_project(
            self.config.single_project_path
        )
        
        print(f"âœ… æå–å®Œæˆ: å…±æ‰¾åˆ° {len(endpoints)} ä¸ªæ¥å£")
        
        # æ˜¾ç¤ºè§£æçš„æ¥å£ç»“æ„
        if self.config.verbose:
            self.display_endpoints("é¡¹ç›®æ¥å£ç»“æ„", endpoints)
        
        # åˆ†ææ¯ä¸ªæ¥å£çš„è°ƒç”¨é“¾
        print("ğŸ” åˆ†ææ¥å£è°ƒç”¨é“¾å’Œä¾èµ–...")
        endpoint_analysis = []
        
        total_endpoints = len(endpoints)
        for i, (name, endpoint) in enumerate(endpoints.items(), 1):
            print(f"  ğŸ“Š åˆ†æè¿›åº¦: {i}/{total_endpoints} ({i/total_endpoints*100:.1f}%) - {endpoint.name}")
            
            # åˆ†æè°ƒç”¨é“¾
            call_chain = self.call_chain_analyzer.analyze_call_chain(
                endpoint, self.config.single_project_path
            )
            
            # åˆ†æSQLæ˜ å°„
            sql_mappings = self.sql_mapper_analyzer.find_related_mappers(
                call_chain, self.config.single_project_path
            )
            
            analysis = {
                "endpoint": endpoint,
                "call_chain": call_chain,
                "sql_mappings": sql_mappings,
                "complexity_score": self._calculate_complexity_score(call_chain, sql_mappings)
            }
            
            endpoint_analysis.append(analysis)
        
        print("âœ… æ¥å£åˆ†æå®Œæˆ")
        
        # æ˜¾ç¤ºåˆ†æç»“æœ
        if self.config.verbose:
            self.display_single_project_analysis(endpoint_analysis)
        
        # ä¿å­˜ç»“æœ
        print("ğŸ’¾ ä¿å­˜åˆ†æç»“æœ...")
        self.save_single_project_results(endpoints, endpoint_analysis)
        
        print(f"ğŸ‰ å•é¡¹ç›®åˆ†æå®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: {self.config.output_dir}")
        print(f"ğŸ“‹ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹æ¥å£è¯¦æƒ…:")
        print(f"   python main.py --show-endpoint <æ¥å£è·¯å¾„> --output {self.config.output_dir}")
        print(f"ğŸ“‹ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç”Ÿæˆè°ƒç”¨é“¾æ ‘:")
        print(f"   python main.py --call-tree <æ¥å£è·¯å¾„> --output {self.config.output_dir}")
    
    def run_migration_analysis(self):
        """è¿è¡Œè¿ç§»åˆ†æï¼ˆåŸæœ‰é€»è¾‘ï¼‰"""
        print("ğŸš€ å¼€å§‹åˆ†ææ–°æ—§é¡¹ç›®æ¥å£...")
        
        # 1. æå–æ¥å£
        print("ğŸ“‹ æ­¥éª¤1: æå–æ—§é¡¹ç›®æ¥å£...")
        old_endpoints = self.endpoint_extractor.extract_from_project(
            self.config.old_project_path
        )
        
        print(f"ğŸ“‹ æ­¥éª¤2: æå–æ–°é¡¹ç›®æ¥å£...")
        new_endpoints = self.endpoint_extractor.extract_from_project(
            self.config.new_project_path
        )
        
        print(f"âœ… æå–å®Œæˆ: æ—§æ¥å£ {len(old_endpoints)} ä¸ª, æ–°æ¥å£ {len(new_endpoints)} ä¸ª")
        
        # æ˜¾ç¤ºè§£æçš„æ¥å£ç»“æ„
        if self.config.verbose:
            self.display_endpoints("æ—§é¡¹ç›®æ¥å£ç»“æ„", old_endpoints)
            self.display_endpoints("æ–°é¡¹ç›®æ¥å£ç»“æ„", new_endpoints)
        
        # 2. åŒ¹é…ç­‰ä»·æ¥å£
        print("ğŸ”„ æ­¥éª¤3: åŒ¹é…ç­‰ä»·æ¥å£...")
        matched_pairs = self.equivalence_matcher.match_endpoints(
            old_endpoints, new_endpoints
        )
        
        print(f"âœ… åŒ¹é…å®Œæˆ: æ‰¾åˆ° {len(matched_pairs)} å¯¹ç­‰ä»·æ¥å£")
        
        # æ˜¾ç¤ºåŒ¹é…çš„æ¥å£å¯¹
        if self.config.verbose and matched_pairs:
            self.display_matched_pairs(matched_pairs)
        
        # 3. åˆ†æè°ƒç”¨é“¾å’ŒSQLæ˜ å°„
        print("ğŸ” æ­¥éª¤4: åˆ†æè°ƒç”¨é“¾å’Œä¾èµ–...")
        migration_plan = self.analyze_migration_plan(matched_pairs)
        
        # æ˜¾ç¤ºè°ƒç”¨é“¾ä¿¡æ¯
        if self.config.verbose and migration_plan:
            self.display_call_chains(migration_plan)
        
        # 4. ä»…åœ¨å¯ç”¨AIåŠŸèƒ½æ—¶ç”Ÿæˆè¿ç§»ä»£ç 
        if self.ai_generator:
            print("ğŸ¤– æ­¥éª¤5: ç”Ÿæˆè¿ç§»ä»£ç ...")
            generated_code = self.generate_migration_code(migration_plan)
        else:
            generated_code = {}
            print("â­ï¸  è·³è¿‡ä»£ç ç”Ÿæˆæ­¥éª¤ï¼ˆæœªå¯ç”¨AIåŠŸèƒ½ï¼‰")
        
        # 5. ä¿å­˜ç»“æœ
        print("ğŸ’¾ æ­¥éª¤6: ä¿å­˜ç»“æœ...")
        self.save_results(old_endpoints, new_endpoints, matched_pairs, generated_code)
        
        print(f"ğŸ‰ {'åˆ†æ' if self.config.analyze_only else 'è¿ç§»'}å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: {self.config.output_dir}")
    
    def display_endpoints(self, title: str, endpoints: Dict):
        """æ˜¾ç¤ºè§£æçš„æ¥å£ç»“æ„"""
        print(f"\n=== {title} ===")
        for i, (name, endpoint) in enumerate(endpoints.items(), 1):
            print(f"{i}. {name}:")
            print(f"  è·¯å¾„: {endpoint.path}")
            print(f"  æ–¹æ³•: {endpoint.method}")
            print(f"  æ§åˆ¶å™¨: {endpoint.controller}")
            print(f"  å¤„ç†å™¨: {endpoint.handler}")
            print(f"  æ–‡ä»¶: {endpoint.file_path}")
            print(f"  è¡Œå·: {endpoint.line_number}")
            print("-" * 40)
    
    def display_matched_pairs(self, matched_pairs: List):
        """æ˜¾ç¤ºåŒ¹é…çš„æ¥å£å¯¹"""
        print("\n=== ç­‰ä»·æ¥å£åŒ¹é…ç»“æœ ===")
        for i, (old_ep, new_ep) in enumerate(matched_pairs, 1):
            print(f"{i}. åŒ¹é…å¯¹:")
            print(f"  æ—§æ¥å£: {old_ep.name} ({old_ep.method} {old_ep.path})")
            print(f"  æ–°æ¥å£: {new_ep.name} ({new_ep.method} {new_ep.path})")
            print(f"  ç›¸ä¼¼åº¦: {getattr(old_ep, 'match_score', {}).get('total_score', 0):.2f}")
            print("-" * 60)
    
    def display_single_project_analysis(self, endpoint_analysis: List[Dict]):
        """æ˜¾ç¤ºå•é¡¹ç›®åˆ†æç»“æœ"""
        print("\n=== å•é¡¹ç›®æ¥å£åˆ†æç»“æœ ===")
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_endpoints = len(endpoint_analysis)
        complex_endpoints = sum(1 for analysis in endpoint_analysis if analysis["complexity_score"] > 5)
        
        print(f"æ€»æ¥å£æ•°: {total_endpoints}")
        print(f"å¤æ‚æ¥å£æ•°: {complex_endpoints}")
        print(f"ç®€å•æ¥å£æ•°: {total_endpoints - complex_endpoints}")
        
        # æŒ‰å¤æ‚åº¦æ’åºæ˜¾ç¤º
        sorted_analysis = sorted(endpoint_analysis, key=lambda x: x["complexity_score"], reverse=True)
        
        for i, analysis in enumerate(sorted_analysis, 1):
            endpoint = analysis["endpoint"]
            call_chain = analysis["call_chain"]
            complexity = analysis["complexity_score"]
            
            print(f"\n{i}. æ¥å£: {endpoint.name}")
            print(f"   è·¯å¾„: {endpoint.method} {endpoint.path}")
            print(f"   æ–‡ä»¶: {endpoint.file_path}:{endpoint.line_number}")
            print(f"   å¤æ‚åº¦: {complexity}")
            
            if call_chain.get("method_calls"):
                print(f"   æ–¹æ³•è°ƒç”¨: {len(call_chain['method_calls'])} ä¸ª")
                if self.config.verbose:
                    for j, call in enumerate(call_chain["method_calls"][:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ª
                        print(f"     {j}. {call.get('object', '')}.{call.get('method', '')}()")
            
            if call_chain.get("sql_statements"):
                print(f"   SQLè¯­å¥: {len(call_chain['sql_statements'])} ä¸ª")
            
            if analysis.get("sql_mappings"):
                print(f"   SQLæ˜ å°„: {len(analysis['sql_mappings'])} ä¸ª")
            
            print("-" * 60)
    
    def display_call_chains(self, migration_plan: List[Dict]):
        """æ˜¾ç¤ºæ¥å£è°ƒç”¨é“¾ä¿¡æ¯"""
        print("\n=== æ¥å£è°ƒç”¨é“¾åˆ†æ ===")
        for i, plan in enumerate(migration_plan, 1):
            old_ep = plan["old_endpoint"]
            print(f"{i}. æ¥å£: {old_ep.name} ({old_ep.method} {old_ep.path})")
            
            call_chain = plan["call_chain"]
            if call_chain.get("method_calls"):
                print("  æ–¹æ³•è°ƒç”¨é“¾:")
                for j, call in enumerate(call_chain["method_calls"], 1):
                    print(f"    {j}. {call.get('object', '')}.{call.get('method', '')}()")
            
            if call_chain.get("service_calls"):
                print("  æœåŠ¡è°ƒç”¨:")
                for j, service in enumerate(call_chain["service_calls"], 1):
                    print(f"    {j}. {service}")
            
            if call_chain.get("dao_calls"):
                print("  DAOè°ƒç”¨:")
                for j, dao in enumerate(call_chain["dao_calls"], 1):
                    print(f"    {j}. {dao}")
            
            if call_chain.get("sql_statements"):
                print("  SQLè¯­å¥:")
                for j, sql in enumerate(call_chain["sql_statements"], 1):
                    print(f"    {j}. {sql[:100]}...")  # åªæ˜¾ç¤ºå‰100ä¸ªå­—ç¬¦
            
            print("-" * 60)
    
    def _calculate_complexity_score(self, call_chain: Dict, sql_mappings: List) -> int:
        """è®¡ç®—æ¥å£å¤æ‚åº¦å¾—åˆ†"""
        score = 0
        
        # æ–¹æ³•è°ƒç”¨æ•°é‡
        method_calls = len(call_chain.get("method_calls", []))
        score += method_calls * 1
        
        # SQLè¯­å¥æ•°é‡
        sql_statements = len(call_chain.get("sql_statements", []))
        score += sql_statements * 2
        
        # SQLæ˜ å°„æ–‡ä»¶æ•°é‡
        score += len(sql_mappings) * 3
        
        # ç›¸å…³æ–‡ä»¶æ•°é‡
        related_files = len(call_chain.get("files", []))
        score += related_files * 1
        
        return score
    
    def analyze_migration_plan(self, matched_pairs: List) -> List[Dict]:
        """åˆ†æè¿ç§»è®¡åˆ’"""
        migration_plan = []
        
        total_pairs = len(matched_pairs)
        print(f"ğŸ” å¼€å§‹åˆ†æ {total_pairs} å¯¹åŒ¹é…æ¥å£çš„è¿ç§»è®¡åˆ’...")
        
        for i, (old_endpoint, new_endpoint) in enumerate(matched_pairs, 1):
            print(f"  ğŸ“Š åˆ†æè¿›åº¦: {i}/{total_pairs} ({i/total_pairs*100:.1f}%) - {old_endpoint.name}")
            
            # åˆ†æè°ƒç”¨é“¾
            call_chain = self.call_chain_analyzer.analyze_call_chain(
                old_endpoint, self.config.old_project_path
            )
            
            # åˆ†æSQLæ˜ å°„
            sql_mappings = self.sql_mapper_analyzer.find_related_mappers(
                call_chain, self.config.old_project_path
            )
            
            # æ”¶é›†éœ€è¦è¿ç§»çš„ä»£ç ä¸Šä¸‹æ–‡
            migration_context = self.collect_migration_context(
                old_endpoint, call_chain, sql_mappings
            )
            
            migration_plan.append({
                "old_endpoint": old_endpoint,
                "new_endpoint": new_endpoint,
                "call_chain": call_chain,
                "sql_mappings": sql_mappings,
                "migration_context": migration_context,
                "estimated_tokens": len(str(migration_context)) // 4  # ç²—ç•¥ä¼°ç®—
            })
        
        print("âœ… è¿ç§»è®¡åˆ’åˆ†æå®Œæˆ")
        return migration_plan
    
    def collect_migration_context(self, old_endpoint, call_chain, sql_mappings):
        """æ”¶é›†è¿ç§»éœ€è¦çš„ä»£ç ä¸Šä¸‹æ–‡"""
        context = {
            "old_endpoint": old_endpoint.__dict__ if hasattr(old_endpoint, '__dict__') else old_endpoint,
            "call_chain": call_chain,
            "sql_mappings": sql_mappings,
            "related_files": set()
        }
        
        # æ”¶é›†æ‰€æœ‰ç›¸å…³æ–‡ä»¶å†…å®¹
        project_root = Path(self.config.old_project_path)
        
        for file_info in call_chain.get("files", []):
            file_path = project_root / file_info["path"]
            if file_path.exists():
                try:
                    content = file_path.read_text(encoding='utf-8')
                    context["related_files"].add({
                        "path": str(file_path.relative_to(project_root)),
                        "content": content[:5000]  # é™åˆ¶å¤§å°
                    })
                except:
                    continue
        
        return context
    
    def generate_migration_code(self, migration_plan: List[Dict]) -> Dict:
        """ç”Ÿæˆè¿ç§»ä»£ç """
        generated_code = {}
        
        total_plans = len(migration_plan)
        print(f"ğŸ¤– å¼€å§‹ç”Ÿæˆ {total_plans} ä¸ªæ¥å£çš„è¿ç§»ä»£ç ...")
        
        for i, plan in enumerate(migration_plan, 1):
            endpoint_name = plan["old_endpoint"].get("name", f"endpoint_{i}")
            print(f"  ğŸ“Š ç”Ÿæˆè¿›åº¦: {i}/{total_plans} ({i/total_plans*100:.1f}%) - {endpoint_name}")
            
            if plan["estimated_tokens"] > self.config.context_window:
                print(f"    âš ï¸  è­¦å‘Š: æ¥å£ä¸Šä¸‹æ–‡è¿‡å¤§ ({plan['estimated_tokens']} tokens)ï¼Œè·³è¿‡ç”Ÿæˆ")
                continue
                
            try:
                generated = self.ai_generator.generate_migration_code(plan)
                generated_code[endpoint_name] = generated
                print(f"    âœ… ç”ŸæˆæˆåŠŸ")
            except Exception as e:
                print(f"    âŒ ç”Ÿæˆå¤±è´¥: {e}")
        
        print("âœ… è¿ç§»ä»£ç ç”Ÿæˆå®Œæˆ")        
        return generated_code
    
    def save_single_project_results(self, endpoints: Dict, endpoint_analysis: List[Dict]):
        """ä¿å­˜å•é¡¹ç›®åˆ†æç»“æœ"""
        # ä¿å­˜æ¥å£ä¿¡æ¯
        with open(f"{self.config.output_dir}/endpoints.json", "w", encoding='utf-8') as f:
            json.dump([e.__dict__ for e in endpoints.values()], f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜åˆ†æç»“æœ
        analysis_data = []
        for analysis in endpoint_analysis:
            endpoint_dict = analysis["endpoint"].__dict__
            analysis_dict = {
                "endpoint": endpoint_dict,
                "call_chain": analysis["call_chain"],
                "sql_mappings": analysis["sql_mappings"],
                "complexity_score": analysis["complexity_score"]
            }
            analysis_data.append(analysis_dict)
        
        with open(f"{self.config.output_dir}/endpoint_analysis.json", "w", encoding='utf-8') as f:
            json.dump(analysis_data, f, indent=2, ensure_ascii=False)
        
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        self._generate_analysis_report(endpoints, endpoint_analysis)
    
    def _generate_analysis_report(self, endpoints: Dict, endpoint_analysis: List[Dict]):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        report_lines = []
        report_lines.append("# é¡¹ç›®æ¥å£åˆ†ææŠ¥å‘Š\n")
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_endpoints = len(endpoint_analysis)
        complex_endpoints = sum(1 for analysis in endpoint_analysis if analysis["complexity_score"] > 5)
        frameworks = set(ep.framework for ep in endpoints.values())
        
        report_lines.append("## ç»Ÿè®¡æ¦‚è§ˆ\n")
        report_lines.append(f"- æ€»æ¥å£æ•°: {total_endpoints}")
        report_lines.append(f"- å¤æ‚æ¥å£æ•°: {complex_endpoints}")
        report_lines.append(f"- ç®€å•æ¥å£æ•°: {total_endpoints - complex_endpoints}")
        report_lines.append(f"- ä½¿ç”¨æ¡†æ¶: {', '.join(frameworks)}")
        report_lines.append("")
        
        # æ¥å£åˆ—è¡¨
        report_lines.append("## æ¥å£è¯¦æƒ…\n")
        sorted_analysis = sorted(endpoint_analysis, key=lambda x: x["complexity_score"], reverse=True)
        
        for i, analysis in enumerate(sorted_analysis, 1):
            endpoint = analysis["endpoint"]
            complexity = analysis["complexity_score"]
            
            report_lines.append(f"### {i}. {endpoint.name}")
            report_lines.append(f"- **è·¯å¾„**: {endpoint.method} {endpoint.path}")
            report_lines.append(f"- **æ–‡ä»¶**: {endpoint.file_path}:{endpoint.line_number}")
            report_lines.append(f"- **å¤æ‚åº¦**: {complexity}")
            report_lines.append(f"- **æ¡†æ¶**: {endpoint.framework}")
            
            call_chain = analysis["call_chain"]
            if call_chain.get("method_calls"):
                report_lines.append(f"- **æ–¹æ³•è°ƒç”¨**: {len(call_chain['method_calls'])} ä¸ª")
            if call_chain.get("sql_statements"):
                report_lines.append(f"- **SQLè¯­å¥**: {len(call_chain['sql_statements'])} ä¸ª")
            if analysis.get("sql_mappings"):
                report_lines.append(f"- **SQLæ˜ å°„**: {len(analysis['sql_mappings'])} ä¸ª")
            
            report_lines.append("")
        
        # ä¿å­˜æŠ¥å‘Š
        with open(f"{self.config.output_dir}/analysis_report.md", "w", encoding='utf-8') as f:
            f.write("\n".join(report_lines))
    
    def save_results(self, *args):
        """ä¿å­˜æ‰€æœ‰ç»“æœåˆ°æ–‡ä»¶"""
        # ä¿å­˜æ—§æ¥å£
        with open(f"{self.config.output_dir}/old_endpoints.json", "w", encoding='utf-8') as f:
            json.dump([e.__dict__ for e in args[0].values()], f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜æ–°æ¥å£
        with open(f"{self.config.output_dir}/new_endpoints.json", "w", encoding='utf-8') as f:
            json.dump([e.__dict__ for e in args[1].values()], f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜åŒ¹é…ç»“æœ
        matched_data = []
        for old, new in args[2]:
            matched_data.append({
                "old": old.__dict__,
                "new": new.__dict__
            })
        with open(f"{self.config.output_dir}/matched_pairs.json", "w", encoding='utf-8') as f:
            json.dump(matched_data, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜ç”Ÿæˆçš„ä»£ç 
        with open(f"{self.config.output_dir}/generated_code.json", "w", encoding='utf-8') as f:
            json.dump(args[3], f, indent=2, ensure_ascii=False)

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ–°æ—§ç³»ç»Ÿæ¥å£è¿ç§»å·¥å…·')
    
    # åˆ›å»ºäº’æ–¥ç»„ï¼šè¦ä¹ˆæ˜¯è¿ç§»æ¨¡å¼ï¼Œè¦ä¹ˆæ˜¯å•é¡¹ç›®æ¨¡å¼ï¼Œè¦ä¹ˆæ˜¯æ¥å£æŸ¥çœ‹æ¨¡å¼ï¼Œè¦ä¹ˆæ˜¯è°ƒç”¨æ ‘ç”Ÿæˆæ¨¡å¼
    mode_group = parser.add_mutually_exclusive_group(required=True)
    mode_group.add_argument('--migrate', action='store_true', help='è¿ç§»æ¨¡å¼ï¼šåˆ†ææ–°æ—§ä¸¤ä¸ªé¡¹ç›®')
    mode_group.add_argument('--single', metavar='PROJECT_PATH', help='å•é¡¹ç›®æ¨¡å¼ï¼šåªåˆ†æä¸€ä¸ªé¡¹ç›®')
    mode_group.add_argument('--show-endpoint', metavar='ENDPOINT_PATH', help='æ˜¾ç¤ºç‰¹å®šæ¥å£çš„ä»£ç å’Œè°ƒç”¨é“¾ï¼Œå¦‚ï¼š/admin/category/page')
    mode_group.add_argument('--call-tree', metavar='ENDPOINT_PATH', help='ç”Ÿæˆç‰¹å®šæ¥å£çš„æ·±åº¦è°ƒç”¨é“¾æ ‘ï¼Œå¦‚ï¼š/user/user/login')
    
    # è¿ç§»æ¨¡å¼å‚æ•°
    parser.add_argument('--old', help='æ—§é¡¹ç›®è·¯å¾„ï¼ˆè¿ç§»æ¨¡å¼å¿…éœ€ï¼‰')
    parser.add_argument('--new', help='æ–°é¡¹ç›®è·¯å¾„ï¼ˆè¿ç§»æ¨¡å¼å¿…éœ€ï¼‰')
    
    # é€šç”¨å‚æ•°
    parser.add_argument('--output', default='./migration_output', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--model', default='gpt-3.5-turbo', help='AIæ¨¡å‹åç§°')
    parser.add_argument('--api-key', help='AI APIå¯†é’¥ï¼Œæˆ–è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡')
    parser.add_argument('-v', '--verbose', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†åˆ†æä¿¡æ¯')
    parser.add_argument('--analyze-only', action='store_true', help='ä»…åˆ†æé¡¹ç›®ç»“æ„ï¼Œä¸ç”Ÿæˆè¿ç§»ä»£ç ')
    
    args = parser.parse_args()
    
    # éªŒè¯å‚æ•°
    if args.migrate:
        if not args.old or not args.new:
            parser.error("è¿ç§»æ¨¡å¼éœ€è¦åŒæ—¶æŒ‡å®š --old å’Œ --new å‚æ•°")
        
        config = Config(
            old_project_path=args.old,
            new_project_path=args.new,
            output_dir=args.output,
            ai_model=args.model,
            api_key=args.api_key,
            verbose=args.verbose,
            analyze_only=args.analyze_only or not (args.api_key or os.getenv("OPENAI_API_KEY")),
            single_mode=False
        )
    elif args.single:  # å•é¡¹ç›®æ¨¡å¼
        config = Config(
            single_project_path=args.single,
            output_dir=args.output,
            ai_model=args.model,
            api_key=args.api_key,
            verbose=args.verbose,
            analyze_only=True,  # å•é¡¹ç›®æ¨¡å¼é»˜è®¤åªåˆ†æ
            single_mode=True
        )
    elif args.show_endpoint:  # æ¥å£æŸ¥çœ‹æ¨¡å¼
        # ç›´æ¥è°ƒç”¨æ¥å£æŸ¥çœ‹åŠŸèƒ½ï¼Œä¸éœ€è¦åˆ›å»ºMigrationTool
        show_endpoint_details(args.show_endpoint, args.output)
        return
    else:  # è°ƒç”¨æ ‘ç”Ÿæˆæ¨¡å¼
        # ç›´æ¥è°ƒç”¨è°ƒç”¨æ ‘ç”ŸæˆåŠŸèƒ½
        generate_call_tree(args.call_tree, args.output)
        return
    
    # è¿è¡Œå·¥å…·
    tool = MigrationTool(config)
    tool.run()

if __name__ == "__main__":
    main()